{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee5edfa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import fastf1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Enable cache\n",
    "fastf1.Cache.enable_cache('../data/cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f0e29e-d161-4ae6-944a-bd35d1e18367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 2025 season schedule\n",
    "print(\"Loading 2025 season schedule...\")\n",
    "season_2025 = fastf1.get_event_schedule(2025)\n",
    "\n",
    "# Filter to actual races (remove testing)\n",
    "races = season_2025[season_2025['EventFormat'] != 'testing'].copy()\n",
    "\n",
    "print(f\"\\nTotal races in 2025: {len(races)}\")\n",
    "print(\"\\nFirst 18 races:\")\n",
    "print(races[['RoundNumber', 'EventName', 'Country', 'EventDate']].head(18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7d1d71-3983-40df-a2a7-4dc9fe249ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load first 18 races\n",
    "races_to_load = races.head(18)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Loading {len(races_to_load)} races...\")\n",
    "print(f\"This will take 10-15 minutes ☕\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "all_race_data = []\n",
    "failed_races = []\n",
    "\n",
    "for idx, race_event in races_to_load.iterrows():\n",
    "    race_name = race_event['EventName']\n",
    "    round_num = race_event['RoundNumber']\n",
    "    \n",
    "    try:\n",
    "        print(f\"[{round_num}/{len(races_to_load)}] Loading {race_name}...\")\n",
    "        \n",
    "        session = fastf1.get_session(2025, race_name, 'R')\n",
    "        session.load()\n",
    "        \n",
    "        results = session.results.copy()\n",
    "        results['RaceName'] = race_name\n",
    "        results['RoundNumber'] = round_num\n",
    "        results['Country'] = race_event['Country']\n",
    "        results['EventDate'] = race_event['EventDate']\n",
    "        \n",
    "        all_race_data.append(results)\n",
    "        print(f\"  ✓ Loaded {len(results)} drivers\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Failed: {e}\")\n",
    "        failed_races.append(race_name)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"✓ Successfully loaded {len(all_race_data)} races\")\n",
    "if failed_races:\n",
    "    print(f\"✗ Failed: {failed_races}\")\n",
    "\n",
    "# Combine all data\n",
    "df_2025 = pd.concat(all_race_data, ignore_index=True)\n",
    "\n",
    "print(f\"\\nDataset Summary:\")\n",
    "print(f\"  Total results: {len(df_2025)}\")\n",
    "print(f\"  Races: {df_2025['RaceName'].nunique()}\")\n",
    "print(f\"  Drivers: {df_2025['Abbreviation'].nunique()}\")\n",
    "print(f\"\\nSample:\")\n",
    "print(df_2025[['RoundNumber', 'RaceName', 'Abbreviation', 'TeamName', 'GridPosition', 'Position']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439054c5-a39d-4d11-982c-1c2c5b96edd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick data check\n",
    "print(\"Data Quality Check:\")\n",
    "print(f\"Missing GridPositions: {df_2025['GridPosition'].isna().sum()}\")\n",
    "print(f\"Missing Positions (DNFs): {df_2025['Position'].isna().sum()}\")\n",
    "print(f\"\\nUnique teams: {df_2025['TeamName'].nunique()}\")\n",
    "print(df_2025['TeamName'].unique())\n",
    "print(f\"\\nUnique drivers: {df_2025['Abbreviation'].nunique()}\")\n",
    "print(df_2025['Abbreviation'].unique())\n",
    "\n",
    "# Check for weird values\n",
    "print(f\"\\nPosition range: {df_2025['Position'].min()} to {df_2025['Position'].max()}\")\n",
    "print(f\"GridPosition range: {df_2025['GridPosition'].min()} to {df_2025['GridPosition'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb40bded-6ddc-4d6d-8048-4fecc9a0be2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by driver and race order\n",
    "df_sorted = df_2025.sort_values(['Abbreviation', 'RoundNumber']).copy()\n",
    "\n",
    "# Calculate rolling average of last 3 race finishes per driver\n",
    "df_sorted['Driver_Last3_AvgFinish'] = (\n",
    "    df_sorted.groupby('Abbreviation')['Position']\n",
    "    .transform(lambda x: x.rolling(window=3, min_periods=1).mean().shift(1))\n",
    ")\n",
    "\n",
    "# Same for teams\n",
    "df_sorted['Team_Last3_AvgFinish'] = (\n",
    "    df_sorted.groupby('TeamName')['Position']\n",
    "    .transform(lambda x: x.rolling(window=3, min_periods=1).mean().shift(1))\n",
    ")\n",
    "\n",
    "# Check it worked\n",
    "print(\"Sample with new features:\")\n",
    "print(df_sorted[['RoundNumber', 'Abbreviation', 'TeamName', 'Position', \n",
    "                 'Driver_Last3_AvgFinish', 'Team_Last3_AvgFinish']].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96259dd7-f8dd-4b46-bf98-eab673b44747",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted['Podium'] = (df_sorted['Position'] <= 3.0).astype(int)\n",
    "\n",
    "print(f\"Podium column added!\")\n",
    "print(f\"Total podiums: {df_sorted['Podium'].sum()}\")\n",
    "print(f\"Total non-podiums: {len(df_sorted) - df_sorted['Podium'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ad416f-fd29-43e7-b75e-2b96e92d029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Prepare the data\n",
    "model_df = df_sorted.copy()\n",
    "\n",
    "# Remove rows with NaN in our new features (first few races per driver)\n",
    "model_df = model_df.dropna(subset=['Driver_Last3_AvgFinish', 'Team_Last3_AvgFinish'])\n",
    "\n",
    "print(f\"Dataset after removing NaN: {len(model_df)} samples\")\n",
    "print(f\"Podiums: {model_df['Podium'].sum()}, Non-podiums: {len(model_df) - model_df['Podium'].sum()}\")\n",
    "\n",
    "# Select features\n",
    "features = ['GridPosition', 'Driver_Last3_AvgFinish', 'Team_Last3_AvgFinish']\n",
    "\n",
    "# Encode categorical features\n",
    "team_encoder = LabelEncoder()\n",
    "driver_encoder = LabelEncoder()\n",
    "\n",
    "model_df['TeamName_encoded'] = team_encoder.fit_transform(model_df['TeamName'])\n",
    "model_df['Driver_encoded'] = driver_encoder.fit_transform(model_df['Abbreviation'])\n",
    "\n",
    "# Add encoded features\n",
    "features.extend(['TeamName_encoded', 'Driver_encoded'])\n",
    "\n",
    "# Prepare X and y\n",
    "X = model_df[features]\n",
    "y = model_df['Podium']\n",
    "\n",
    "print(f\"\\nFeatures: {features}\")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c240e324-4f34-494d-9979-eb44d1f0af6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data: Use races 1-15 for training, 16-18 for testing\n",
    "# This is more realistic than random split (we predict future races)\n",
    "train_mask = model_df['RoundNumber'] <= 15\n",
    "test_mask = model_df['RoundNumber'] > 15\n",
    "\n",
    "X_train = X[train_mask]\n",
    "X_test = X[test_mask]\n",
    "y_train = y[train_mask]\n",
    "y_test = y[test_mask]\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples ({y_train.sum()} podiums)\")\n",
    "print(f\"Test set: {len(X_test)} samples ({y_test.sum()} podiums)\")\n",
    "\n",
    "# Train Random Forest\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'  # Handle class imbalance\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n✓ Model trained!\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"MODEL PERFORMANCE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Accuracy: {accuracy*100:.1f}%\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['No Podium', 'Podium']))\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e886372f-d80b-4caa-8967-61533d2973b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load qualifying data for all 18 races\n",
    "print(\"Loading qualifying sessions...\")\n",
    "\n",
    "quali_data = []\n",
    "\n",
    "for round_num in range(1, 19):\n",
    "    race_name = races.loc[races['RoundNumber'] == round_num, 'EventName'].values[0]\n",
    "    \n",
    "    try:\n",
    "        print(f\"Loading quali for Round {round_num}: {race_name}...\")\n",
    "        \n",
    "        # Load qualifying session\n",
    "        quali = fastf1.get_session(2025, race_name, 'Q')\n",
    "        quali.load()\n",
    "        \n",
    "        # Get results\n",
    "        quali_results = quali.results[['Abbreviation', 'Position', 'Q3', 'Q2', 'Q1']].copy()\n",
    "        quali_results['RoundNumber'] = round_num\n",
    "        quali_results['RaceName'] = race_name\n",
    "        quali_results.rename(columns={'Position': 'Quali_Position'}, inplace=True)\n",
    "        \n",
    "        quali_data.append(quali_results)\n",
    "        print(f\"  ✓ Loaded\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Failed: {e}\")\n",
    "\n",
    "# Combine all quali data\n",
    "df_quali = pd.concat(quali_data, ignore_index=True)\n",
    "\n",
    "print(f\"\\n✓ Loaded qualifying data for {len(df_quali)} entries\")\n",
    "print(f\"\\nSample:\")\n",
    "print(df_quali[['RoundNumber', 'RaceName', 'Abbreviation', 'Quali_Position']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a1eb6e-b954-491b-89bf-388dbfe1a98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge qualifying data with our sorted race data\n",
    "df_sorted = df_sorted.merge(\n",
    "    df_quali[['RoundNumber', 'Abbreviation', 'Quali_Position']], \n",
    "    on=['RoundNumber', 'Abbreviation'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Feature 1: Grid Penalty (boolean)\n",
    "df_sorted['Grid_Penalty'] = (df_sorted['GridPosition'] != df_sorted['Quali_Position']).astype(int)\n",
    "\n",
    "# Feature 2: Penalty Size (how many places)\n",
    "df_sorted['Penalty_Places'] = df_sorted['GridPosition'] - df_sorted['Quali_Position']\n",
    "\n",
    "# Feature 3: Gap to pole position (we'll use quali position as proxy for now)\n",
    "df_sorted['Gap_To_Pole'] = df_sorted['Quali_Position'] - 1\n",
    "\n",
    "# Check it worked\n",
    "print(\"Qualifying features added!\")\n",
    "print(f\"\\nDrivers with grid penalties: {df_sorted['Grid_Penalty'].sum()}\")\n",
    "print(f\"\\nSample with new features:\")\n",
    "print(df_sorted[['RoundNumber', 'Abbreviation', 'Quali_Position', 'GridPosition', \n",
    "                 'Grid_Penalty', 'Penalty_Places']].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5196ff6b-597d-4b73-a030-3c22fab614e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weather data for all races\n",
    "print(\"Loading weather data...\")\n",
    "\n",
    "weather_data = []\n",
    "\n",
    "for round_num in range(1, 19):\n",
    "    race_name = races.loc[races['RoundNumber'] == round_num, 'EventName'].values[0]\n",
    "    \n",
    "    try:\n",
    "        print(f\"Loading weather for Round {round_num}: {race_name}...\")\n",
    "        \n",
    "        # Load race session (weather is tied to race)\n",
    "        session = fastf1.get_session(2025, race_name, 'R')\n",
    "        session.load()\n",
    "        \n",
    "        # Get weather at race start (first timestamp)\n",
    "        weather = session.weather_data\n",
    "        if len(weather) > 0:\n",
    "            race_start_weather = weather.iloc[0]  # First weather reading\n",
    "            \n",
    "            weather_data.append({\n",
    "                'RoundNumber': round_num,\n",
    "                'RaceName': race_name,\n",
    "                'AirTemp': race_start_weather['AirTemp'],\n",
    "                'TrackTemp': race_start_weather['TrackTemp'],\n",
    "                'Humidity': race_start_weather['Humidity'],\n",
    "                'Rainfall': race_start_weather['Rainfall']\n",
    "            })\n",
    "            print(f\"  ✓ Loaded\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Failed: {e}\")\n",
    "\n",
    "# Create weather dataframe\n",
    "df_weather = pd.DataFrame(weather_data)\n",
    "\n",
    "print(f\"\\n✓ Loaded weather for {len(df_weather)} races\")\n",
    "print(f\"\\nSample:\")\n",
    "print(df_weather.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7447c486-93f1-40f3-9ea7-11827ac87e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge weather data\n",
    "df_sorted = df_sorted.merge(\n",
    "    df_weather[['RoundNumber', 'AirTemp', 'TrackTemp', 'Humidity', 'Rainfall']], \n",
    "    on='RoundNumber', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(\"✓ Weather data merged\")\n",
    "\n",
    "# Now calculate gap to teammate in qualifying\n",
    "# First, find who are teammates (same team)\n",
    "df_quali_with_team = df_quali.merge(\n",
    "    df_sorted[['RoundNumber', 'Abbreviation', 'TeamName']].drop_duplicates(),\n",
    "    on=['RoundNumber', 'Abbreviation'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# For each driver, find their teammate's quali position\n",
    "teammate_quali = []\n",
    "\n",
    "for idx, row in df_quali_with_team.iterrows():\n",
    "    # Find teammate (same team, different driver, same round)\n",
    "    teammate = df_quali_with_team[\n",
    "        (df_quali_with_team['RoundNumber'] == row['RoundNumber']) &\n",
    "        (df_quali_with_team['TeamName'] == row['TeamName']) &\n",
    "        (df_quali_with_team['Abbreviation'] != row['Abbreviation'])\n",
    "    ]\n",
    "    \n",
    "    if len(teammate) > 0:\n",
    "        teammate_pos = teammate.iloc[0]['Quali_Position']\n",
    "        gap = row['Quali_Position'] - teammate_pos\n",
    "    else:\n",
    "        gap = 0  # No teammate (shouldn't happen, but just in case)\n",
    "    \n",
    "    teammate_quali.append({\n",
    "        'RoundNumber': row['RoundNumber'],\n",
    "        'Abbreviation': row['Abbreviation'],\n",
    "        'Gap_To_Teammate_Quali': gap,\n",
    "        'Beat_Teammate': 1 if gap < 0 else 0\n",
    "    })\n",
    "\n",
    "df_teammate = pd.DataFrame(teammate_quali)\n",
    "\n",
    "# Merge with main dataframe\n",
    "df_sorted = df_sorted.merge(\n",
    "    df_teammate[['RoundNumber', 'Abbreviation', 'Gap_To_Teammate_Quali', 'Beat_Teammate']],\n",
    "    on=['RoundNumber', 'Abbreviation'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(\"✓ Teammate gap calculated\")\n",
    "print(f\"\\nNew features summary:\")\n",
    "print(f\"Total features now: {len(df_sorted.columns)}\")\n",
    "print(f\"\\nSample with all new features:\")\n",
    "print(df_sorted[['RoundNumber', 'Abbreviation', 'TeamName', 'Quali_Position', \n",
    "                 'Gap_To_Teammate_Quali', 'Beat_Teammate', 'TrackTemp', 'Rainfall']].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3785f36-bbc7-4881-a823-022be3c99aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data with new features\n",
    "model_df = df_sorted.copy()\n",
    "\n",
    "# Remove rows with NaN\n",
    "model_df = model_df.dropna(subset=['Driver_Last3_AvgFinish', 'Team_Last3_AvgFinish', \n",
    "                                     'Gap_To_Teammate_Quali', 'TrackTemp'])\n",
    "\n",
    "print(f\"Dataset after removing NaN: {len(model_df)} samples\")\n",
    "print(f\"Podiums: {model_df['Podium'].sum()}, Non-podiums: {len(model_df) - model_df['Podium'].sum()}\")\n",
    "\n",
    "# Select ALL features\n",
    "features = [\n",
    "    'GridPosition',\n",
    "    'Quali_Position', \n",
    "    'Grid_Penalty',\n",
    "    'Penalty_Places',\n",
    "    'Gap_To_Pole',\n",
    "    'Driver_Last3_AvgFinish',\n",
    "    'Team_Last3_AvgFinish',\n",
    "    'Gap_To_Teammate_Quali',\n",
    "    'Beat_Teammate',\n",
    "    'AirTemp',\n",
    "    'TrackTemp',\n",
    "    'Humidity',\n",
    "    'Rainfall'\n",
    "]\n",
    "\n",
    "# Encode categorical\n",
    "team_encoder = LabelEncoder()\n",
    "driver_encoder = LabelEncoder()\n",
    "\n",
    "model_df['TeamName_encoded'] = team_encoder.fit_transform(model_df['TeamName'])\n",
    "model_df['Driver_encoded'] = driver_encoder.fit_transform(model_df['Abbreviation'])\n",
    "\n",
    "features.extend(['TeamName_encoded', 'Driver_encoded'])\n",
    "\n",
    "# Prepare X and y\n",
    "X = model_df[features]\n",
    "y = model_df['Podium']\n",
    "\n",
    "print(f\"\\nTotal features: {len(features)}\")\n",
    "print(f\"Features: {features}\")\n",
    "print(f\"\\nX shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07eaee0-bb5d-498c-8250-62c27960354c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data: races 1-15 train, 16-18 test\n",
    "train_mask = model_df['RoundNumber'] <= 15\n",
    "test_mask = model_df['RoundNumber'] > 15\n",
    "\n",
    "X_train = X[train_mask]\n",
    "X_test = X[test_mask]\n",
    "y_train = y[train_mask]\n",
    "y_test = y[test_mask]\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples ({y_train.sum()} podiums)\")\n",
    "print(f\"Test set: {len(X_test)} samples ({y_test.sum()} podiums)\")\n",
    "\n",
    "# Train Random Forest with new features\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"\\n✓ Model trained!\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"MODEL PERFORMANCE (With New Features)\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Accuracy: {accuracy*100:.1f}%\")\n",
    "print(f\"Previous accuracy (5 features): 90.0%\")\n",
    "print(f\"Improvement: {(accuracy - 0.90)*100:+.1f}%\\n\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['No Podium', 'Podium']))\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa55ab2b-6e14-435e-aef8-c6c4d1e8f583",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Train XGBoost model\n",
    "print(\"Training XGBoost model...\")\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    scale_pos_weight=(len(y_train) - y_train.sum()) / y_train.sum(),  # Handle imbalance\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "print(\"✓ XGBoost model trained!\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"XGBoost PERFORMANCE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"XGBoost Accuracy: {accuracy_xgb*100:.1f}%\")\n",
    "print(f\"Random Forest Accuracy: {accuracy*100:.1f}%\")\n",
    "print(f\"Improvement: {(accuracy_xgb - accuracy)*100:+.1f}%\\n\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb, target_names=['No Podium', 'Podium']))\n",
    "\n",
    "# Feature importance for XGBoost\n",
    "feature_importance_xgb = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': xgb_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features (XGBoost):\")\n",
    "print(feature_importance_xgb.head(10))\n",
    "\n",
    "# Compare predictions\n",
    "comparison = pd.DataFrame({\n",
    "    'Actual': y_test.values,\n",
    "    'RF_Pred': y_pred,\n",
    "    'XGB_Pred': y_pred_xgb\n",
    "})\n",
    "comparison['RF_Correct'] = (comparison['Actual'] == comparison['RF_Pred']).astype(int)\n",
    "comparison['XGB_Correct'] = (comparison['Actual'] == comparison['XGB_Pred']).astype(int)\n",
    "\n",
    "print(f\"\\nPrediction Comparison:\")\n",
    "print(f\"Random Forest correct: {comparison['RF_Correct'].sum()}/{len(comparison)}\")\n",
    "print(f\"XGBoost correct: {comparison['XGB_Correct'].sum()}/{len(comparison)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73eb2c3-dd5e-4c92-b23f-aced3c121470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what races are left in 2025\n",
    "remaining_races = races[races['RoundNumber'] > 18]\n",
    "\n",
    "print(\"Remaining races in 2025:\")\n",
    "print(remaining_races[['RoundNumber', 'EventName', 'Country', 'EventDate']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf763ba-a38e-4760-abb1-c67e7e2080d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on races 19-21. getting the test data and features.\n",
    "# Load races 19-21 (already happened)\n",
    "print(\"Loading races 19-21 for validation...\")\n",
    "\n",
    "validation_races = []\n",
    "\n",
    "for round_num in [19, 20, 21]:\n",
    "    race_name = races.loc[races['RoundNumber'] == round_num, 'EventName'].values[0]\n",
    "    \n",
    "    try:\n",
    "        print(f\"Loading Round {round_num}: {race_name}...\")\n",
    "        session = fastf1.get_session(2025, race_name, 'R')\n",
    "        session.load()\n",
    "        \n",
    "        results = session.results.copy()\n",
    "        results['RaceName'] = race_name\n",
    "        results['RoundNumber'] = round_num\n",
    "        \n",
    "        validation_races.append(results)\n",
    "        print(f\"  ✓ Loaded\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Failed: {e}\")\n",
    "\n",
    "if validation_races:\n",
    "    df_validation = pd.concat(validation_races, ignore_index=True)\n",
    "    print(f\"\\n✓ Loaded {len(df_validation)} results from {len(validation_races)} races\")\n",
    "    print(f\"\\nSample:\")\n",
    "    print(df_validation[['RoundNumber', 'RaceName', 'Abbreviation', 'GridPosition', 'Position']].head(10))\n",
    "else:\n",
    "    print(\"\\nNo validation races loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef000a06-08bf-48a0-a8b0-6afd5f7637bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to add all the features to validation data like we did for training data\n",
    "\n",
    "# First, let's add the basic features we can calculate\n",
    "df_validation['Podium'] = (df_validation['Position'] <= 3.0).astype(int)\n",
    "\n",
    "# For form features, we need data from races 1-21\n",
    "# Let's combine our training data (races 1-18) with validation (19-21)\n",
    "df_all = pd.concat([df_sorted, df_validation], ignore_index=True).sort_values(['Abbreviation', 'RoundNumber'])\n",
    "\n",
    "# Recalculate rolling features for ALL races\n",
    "df_all['Driver_Last3_AvgFinish'] = (\n",
    "    df_all.groupby('Abbreviation')['Position']\n",
    "    .transform(lambda x: x.rolling(window=3, min_periods=1).mean().shift(1))\n",
    ")\n",
    "\n",
    "df_all['Team_Last3_AvgFinish'] = (\n",
    "    df_all.groupby('TeamName')['Position']\n",
    "    .transform(lambda x: x.rolling(window=3, min_periods=1).mean().shift(1))\n",
    ")\n",
    "\n",
    "# Filter to just validation races (19-21)\n",
    "df_val_with_features = df_all[df_all['RoundNumber'].isin([19, 20, 21])].copy()\n",
    "\n",
    "print(f\"Validation data with form features: {len(df_val_with_features)} samples\")\n",
    "print(f\"\\nSample:\")\n",
    "print(df_val_with_features[['RoundNumber', 'Abbreviation', 'Position', 'Driver_Last3_AvgFinish']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e91d38-2537-42a9-a83c-5929a1b914a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load qualifying data for races 19-21\n",
    "print(\"Loading qualifying data for validation races...\")\n",
    "\n",
    "val_quali_data = []\n",
    "\n",
    "for round_num in [19, 20, 21]:\n",
    "    race_name = races.loc[races['RoundNumber'] == round_num, 'EventName'].values[0]\n",
    "    \n",
    "    try:\n",
    "        print(f\"Loading quali for Round {round_num}: {race_name}...\")\n",
    "        quali = fastf1.get_session(2025, race_name, 'Q')\n",
    "        quali.load()\n",
    "        \n",
    "        quali_results = quali.results[['Abbreviation', 'Position']].copy()\n",
    "        quali_results['RoundNumber'] = round_num\n",
    "        quali_results.rename(columns={'Position': 'Quali_Position'}, inplace=True)\n",
    "        \n",
    "        val_quali_data.append(quali_results)\n",
    "        print(f\"  ✓ Loaded\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Failed: {e}\")\n",
    "\n",
    "df_val_quali = pd.concat(val_quali_data, ignore_index=True)\n",
    "\n",
    "# Load weather data for races 19-21\n",
    "print(\"\\nLoading weather data for validation races...\")\n",
    "\n",
    "val_weather_data = []\n",
    "\n",
    "for round_num in [19, 20, 21]:\n",
    "    race_name = races.loc[races['RoundNumber'] == round_num, 'EventName'].values[0]\n",
    "    \n",
    "    try:\n",
    "        print(f\"Loading weather for Round {round_num}: {race_name}...\")\n",
    "        session = fastf1.get_session(2025, race_name, 'R')\n",
    "        session.load()\n",
    "        \n",
    "        weather = session.weather_data\n",
    "        if len(weather) > 0:\n",
    "            race_start_weather = weather.iloc[0]\n",
    "            \n",
    "            val_weather_data.append({\n",
    "                'RoundNumber': round_num,\n",
    "                'AirTemp': race_start_weather['AirTemp'],\n",
    "                'TrackTemp': race_start_weather['TrackTemp'],\n",
    "                'Humidity': race_start_weather['Humidity'],\n",
    "                'Rainfall': race_start_weather['Rainfall']\n",
    "            })\n",
    "            print(f\"  ✓ Loaded\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Failed: {e}\")\n",
    "\n",
    "df_val_weather = pd.DataFrame(val_weather_data)\n",
    "\n",
    "print(f\"\\n✓ Quali data: {len(df_val_quali)} entries\")\n",
    "print(f\"✓ Weather data: {len(df_val_weather)} races\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e24d7d-1343-4ec3-a339-ea1ed3c5ce34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop existing quali/weather columns if they exist\n",
    "cols_to_drop = ['Quali_Position', 'AirTemp', 'TrackTemp', 'Humidity', 'Rainfall', \n",
    "                'Grid_Penalty', 'Penalty_Places', 'Gap_To_Pole']\n",
    "\n",
    "for col in cols_to_drop:\n",
    "    if col in df_val_with_features.columns:\n",
    "        df_val_with_features = df_val_with_features.drop(columns=[col])\n",
    "\n",
    "# Now merge quali data\n",
    "df_val_with_features = df_val_with_features.merge(\n",
    "    df_val_quali[['RoundNumber', 'Abbreviation', 'Quali_Position']],\n",
    "    on=['RoundNumber', 'Abbreviation'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Merge weather data\n",
    "df_val_with_features = df_val_with_features.merge(\n",
    "    df_val_weather[['RoundNumber', 'AirTemp', 'TrackTemp', 'Humidity', 'Rainfall']],\n",
    "    on='RoundNumber',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Calculate penalty features\n",
    "df_val_with_features['Grid_Penalty'] = (df_val_with_features['GridPosition'] != df_val_with_features['Quali_Position']).astype(int)\n",
    "df_val_with_features['Penalty_Places'] = df_val_with_features['GridPosition'] - df_val_with_features['Quali_Position']\n",
    "df_val_with_features['Gap_To_Pole'] = df_val_with_features['Quali_Position'] - 1\n",
    "df_val_with_features['Gap_To_Teammate_Quali'] = 0  # Simplification\n",
    "df_val_with_features['Beat_Teammate'] = 0\n",
    "\n",
    "# Encode\n",
    "df_val_with_features['TeamName_encoded'] = team_encoder.transform(df_val_with_features['TeamName'])\n",
    "df_val_with_features['Driver_encoded'] = driver_encoder.transform(df_val_with_features['Abbreviation'])\n",
    "\n",
    "# Prepare features\n",
    "X_val = df_val_with_features[features].fillna(0)\n",
    "y_val = df_val_with_features['Podium']\n",
    "\n",
    "print(f\"✓ Validation set prepared: {len(X_val)} samples\")\n",
    "print(f\"Actual podiums: {y_val.sum()}\")\n",
    "\n",
    "# Predict\n",
    "y_val_pred = rf_model.predict(X_val)\n",
    "y_val_prob = rf_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "print(f\"Predicted podiums: {y_val_pred.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc2cbc4-c9fa-427c-b856-4e67de75161c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Better prediction: Pick top 3 per race\n",
    "print(\"IMPROVED PREDICTIONS (Top 3 per race):\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "correct_predictions = 0\n",
    "total_podiums = 0\n",
    "\n",
    "for round_num in [19, 20, 21]:\n",
    "    race_data = results_comparison[results_comparison['RoundNumber'] == round_num].copy()\n",
    "    race_name = race_data['RaceName'].iloc[0]\n",
    "    \n",
    "    # Sort by podium probability and pick top 3\n",
    "    top3_predicted = race_data.nlargest(3, 'Podium_Probability')\n",
    "    actual_podium = race_data[race_data['Podium'] == 1]\n",
    "    \n",
    "    print(f\"\\nRound {round_num}: {race_name}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    print(\"Predicted Podium (Top 3 by probability):\")\n",
    "    for i, row in top3_predicted.iterrows():\n",
    "        actual_pos = row['Position']\n",
    "        was_correct = \"✓\" if row['Podium'] == 1 else \"✗\"\n",
    "        print(f\"  {was_correct} {row['Abbreviation']:3s} ({row['TeamName']:20s}) - {row['Podium_Probability']*100:.1f}% prob, actual P{int(actual_pos)}\")\n",
    "    \n",
    "    print(\"\\nActual Podium:\")\n",
    "    for i, row in actual_podium.iterrows():\n",
    "        print(f\"  P{int(row['Position'])}: {row['Abbreviation']} ({row['TeamName']}) from P{int(row['GridPosition'])}\")\n",
    "    \n",
    "    # Count correct predictions\n",
    "    predicted_drivers = set(top3_predicted['Abbreviation'])\n",
    "    actual_drivers = set(actual_podium['Abbreviation'])\n",
    "    correct = len(predicted_drivers & actual_drivers)\n",
    "    \n",
    "    correct_predictions += correct\n",
    "    total_podiums += 3\n",
    "    \n",
    "    print(f\"\\nCorrect: {correct}/3\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"OVERALL: {correct_predictions}/{total_podiums} podiums predicted correctly ({correct_predictions/total_podiums*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf781c1-5062-403e-825a-533a8cfa7199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace rolling average with exponential weighted mean\n",
    "# (More weight on recent races)\n",
    "\n",
    "df_sorted['Driver_Last3_AvgFinish'] = (\n",
    "    df_sorted.groupby('Abbreviation')['Position']\n",
    "    .transform(lambda x: x.ewm(span=3, adjust=False).mean().shift(1))\n",
    ")\n",
    "\n",
    "df_sorted['Team_Last3_AvgFinish'] = (\n",
    "    df_sorted.groupby('TeamName')['Position']\n",
    "    .transform(lambda x: x.ewm(span=3, adjust=False).mean().shift(1))\n",
    ")\n",
    "\n",
    "print(\"✓ Exponential weighting applied to form features\")\n",
    "print(\"\\nExample - Verstappen's form over season:\")\n",
    "ver_sample = df_sorted[df_sorted['Abbreviation'] == 'VER'][['RoundNumber', 'Position', 'Driver_Last3_AvgFinish']].head(15)\n",
    "print(ver_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38365d66-b4e0-4a12-9ad5-99e12b293706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain model with exponentially weighted features\n",
    "print(\"Retraining model with exponentially weighted form features...\")\n",
    "\n",
    "# Prepare data (same as before)\n",
    "model_df = df_sorted.copy()\n",
    "model_df = model_df.dropna(subset=['Driver_Last3_AvgFinish', 'Team_Last3_AvgFinish', \n",
    "                                     'Gap_To_Teammate_Quali', 'TrackTemp'])\n",
    "\n",
    "print(f\"Dataset: {len(model_df)} samples\")\n",
    "\n",
    "# Same features as before\n",
    "features = [\n",
    "    'GridPosition',\n",
    "    'Quali_Position', \n",
    "    'Grid_Penalty',\n",
    "    'Penalty_Places',\n",
    "    'Gap_To_Pole',\n",
    "    'Driver_Last3_AvgFinish',  # Now exponentially weighted!\n",
    "    'Team_Last3_AvgFinish',    # Now exponentially weighted!\n",
    "    'Gap_To_Teammate_Quali',\n",
    "    'Beat_Teammate',\n",
    "    'AirTemp',\n",
    "    'TrackTemp',\n",
    "    'Humidity',\n",
    "    'Rainfall'\n",
    "]\n",
    "\n",
    "# Encode\n",
    "team_encoder = LabelEncoder()\n",
    "driver_encoder = LabelEncoder()\n",
    "model_df['TeamName_encoded'] = team_encoder.fit_transform(model_df['TeamName'])\n",
    "model_df['Driver_encoded'] = driver_encoder.fit_transform(model_df['Abbreviation'])\n",
    "features.extend(['TeamName_encoded', 'Driver_encoded'])\n",
    "\n",
    "# Prepare X, y\n",
    "X = model_df[features]\n",
    "y = model_df['Podium']\n",
    "\n",
    "# Split\n",
    "train_mask = model_df['RoundNumber'] <= 15\n",
    "test_mask = model_df['RoundNumber'] > 15\n",
    "\n",
    "X_train = X[train_mask]\n",
    "X_test = X[test_mask]\n",
    "y_train = y[train_mask]\n",
    "y_test = y[test_mask]\n",
    "\n",
    "# Train Random Forest\n",
    "rf_model_ewm = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "rf_model_ewm.fit(X_train, y_train)\n",
    "print(\"✓ Model retrained with exponential weighting!\")\n",
    "\n",
    "# Evaluate on test set (races 16-18)\n",
    "y_pred = rf_model_ewm.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"TEST SET PERFORMANCE (Races 16-18)\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"New accuracy (exponential weighting): {accuracy*100:.1f}%\")\n",
    "print(f\"Previous accuracy (simple average): 90.0%\")\n",
    "print(f\"Change: {(accuracy - 0.90)*100:+.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23744f77-70f4-48e3-9c63-63d3780da386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on validation races (19-21) with new exponential weighting\n",
    "\n",
    "# First, recalculate form features for ALL races including validation\n",
    "df_all_ewm = pd.concat([df_sorted, df_validation], ignore_index=True).sort_values(['Abbreviation', 'RoundNumber'])\n",
    "\n",
    "df_all_ewm['Driver_Last3_AvgFinish'] = (\n",
    "    df_all_ewm.groupby('Abbreviation')['Position']\n",
    "    .transform(lambda x: x.ewm(span=3, adjust=False).mean().shift(1))\n",
    ")\n",
    "\n",
    "df_all_ewm['Team_Last3_AvgFinish'] = (\n",
    "    df_all_ewm.groupby('TeamName')['Position']\n",
    "    .transform(lambda x: x.ewm(span=3, adjust=False).mean().shift(1))\n",
    ")\n",
    "\n",
    "# Filter to validation races\n",
    "df_val_ewm = df_all_ewm[df_all_ewm['RoundNumber'].isin([19, 20, 21])].copy()\n",
    "\n",
    "# Drop existing quali/weather columns if they exist\n",
    "cols_to_drop = ['Quali_Position', 'AirTemp', 'TrackTemp', 'Humidity', 'Rainfall', \n",
    "                'Grid_Penalty', 'Penalty_Places', 'Gap_To_Pole', 'Gap_To_Teammate_Quali', 'Beat_Teammate']\n",
    "for col in cols_to_drop:\n",
    "    if col in df_val_ewm.columns:\n",
    "        df_val_ewm = df_val_ewm.drop(columns=[col])\n",
    "\n",
    "# Now merge quali and weather\n",
    "df_val_ewm = df_val_ewm.merge(\n",
    "    df_val_quali[['RoundNumber', 'Abbreviation', 'Quali_Position']],\n",
    "    on=['RoundNumber', 'Abbreviation'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "df_val_ewm = df_val_ewm.merge(\n",
    "    df_val_weather[['RoundNumber', 'AirTemp', 'TrackTemp', 'Humidity', 'Rainfall']],\n",
    "    on='RoundNumber',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Calculate other features\n",
    "df_val_ewm['Grid_Penalty'] = (df_val_ewm['GridPosition'] != df_val_ewm['Quali_Position']).astype(int)\n",
    "df_val_ewm['Penalty_Places'] = df_val_ewm['GridPosition'] - df_val_ewm['Quali_Position']\n",
    "df_val_ewm['Gap_To_Pole'] = df_val_ewm['Quali_Position'] - 1\n",
    "df_val_ewm['Gap_To_Teammate_Quali'] = 0\n",
    "df_val_ewm['Beat_Teammate'] = 0\n",
    "\n",
    "# Encode\n",
    "df_val_ewm['TeamName_encoded'] = team_encoder.transform(df_val_ewm['TeamName'])\n",
    "df_val_ewm['Driver_encoded'] = driver_encoder.transform(df_val_ewm['Abbreviation'])\n",
    "\n",
    "# Prepare features\n",
    "X_val_ewm = df_val_ewm[features].fillna(0)\n",
    "y_val_ewm = df_val_ewm['Podium']\n",
    "\n",
    "# Predict with new model\n",
    "y_val_pred_ewm = rf_model_ewm.predict(X_val_ewm)\n",
    "y_val_prob_ewm = rf_model_ewm.predict_proba(X_val_ewm)[:, 1]\n",
    "\n",
    "val_accuracy_ewm = accuracy_score(y_val_ewm, y_val_pred_ewm)\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"VALIDATION (Races 19-21) - Exponential Weighting\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"New accuracy: {val_accuracy_ewm*100:.1f}%\")\n",
    "print(f\"Previous accuracy: 88.3%\")\n",
    "print(f\"Improvement: {(val_accuracy_ewm - 0.883)*100:+.1f}%\")\n",
    "\n",
    "# Race-by-race predictions\n",
    "results_comparison_ewm = df_val_ewm[['RoundNumber', 'RaceName', 'Abbreviation', \n",
    "                                      'TeamName', 'GridPosition', 'Position', 'Podium']].copy()\n",
    "results_comparison_ewm['Podium_Probability'] = y_val_prob_ewm\n",
    "\n",
    "correct_predictions = 0\n",
    "for round_num in [19, 20, 21]:\n",
    "    race_data = results_comparison_ewm[results_comparison_ewm['RoundNumber'] == round_num].copy()\n",
    "    race_name = race_data['RaceName'].iloc[0]\n",
    "    \n",
    "    top3_predicted = race_data.nlargest(3, 'Podium_Probability')\n",
    "    actual_podium = race_data[race_data['Podium'] == 1]\n",
    "    \n",
    "    predicted_drivers = set(top3_predicted['Abbreviation'])\n",
    "    actual_drivers = set(actual_podium['Abbreviation'])\n",
    "    correct = len(predicted_drivers & actual_drivers)\n",
    "    correct_predictions += correct\n",
    "    \n",
    "    print(f\"\\nRound {round_num}: {race_name} - {correct}/3 correct\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"OVERALL: {correct_predictions}/9 podiums correct ({correct_predictions/9*100:.1f}%)\")\n",
    "print(f\"Previous: 6/9 (66.7%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b89af9-1a9d-4891-940e-8855964af2fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
